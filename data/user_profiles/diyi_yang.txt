I am an assistant professor in the Computer Science Department at Stanford, affiliated with the Stanford NLP Group, Stanford HCI Group, Stanford AI Lab (SAIL), and Stanford Human-Centered Artificial Intelligence (HAI). I am interested in Socially Aware NLP, Large Language Models (LLMs) and Human-AI Interaction, with a focus on how LLMs can augment human capabilities across research, work and well-being. My research goal is to design human-centered AI systems that are not only technically capable, but also meaningfully connected to how people think, interact, and collaborate.

Prospective students and postdocs, please check out this page on how to get involved.

Recent Projects
Generative Interaction: Generative UI, Generative User Modeling (GUM)
Human-Agent Collaboration:Co-Gym, Future of Work with AI Agents
LLMs and Large Audio Models: DiVA, Talk Arena, CAVA
Social Skill Training via LLMs: AI Partner and AI Mentor (APAM), Rehearsal
Dialects and Low-resource Context: VALUE, Multi-VALUE, DADA
AI, Culture, and Society: CoMPost, NormBank, CultureBank, Unintended Impact
About Me
Assistant Professor, Computer Science Department at Stanford, 2022.9 - Present
Assistant Professor, School of Interactive Computing at Georgia Tech, 2019.8 - 2022.8
Ph.D., Language Technologies Institute at Carnegie Mellon University, 2013 - 2019
B.S., ACM Honored Class at Shanghai Jiao Tong University, 2009 - 2013


Snapshot & Focus

Diyi Yang is an Assistant Professor of Computer Science at Stanford University, affiliated with the Stanford NLP Group, HCI Group, SAIL, and HAI. Her lab develops socially aware, human-centered language technologies—systems that can understand social context, support human communication, and behave responsibly across cultures and dialects. Her work bridges natural language processing (NLP), human-computer interaction (HCI), and computational social science.

1. Human-Centered LLM Interaction & Collaboration

A major strand of her research focuses on improving how humans interact and collaborate with large language models (LLMs).

Generative Interfaces (GenUI): Proposes systems that generate interactive user interfaces tailored to user goals, moving beyond static text responses.

General User Models (GUM): Builds dynamic user representations learned from real-world computer use (e.g., screenshots or activity traces) to enable proactive, context-aware assistants.

AI and the Future of Work: Studies human-AI collaboration, introducing frameworks like the Human Agency Scale and the WORKBank dataset to measure how workers want to use AI for automation and augmentation.

2. Speech & Audio Interaction with LLMs

Yang’s group develops systems for voice-based collaboration between humans and AI.

Projects like DiVA (Distilled Voice Assistant) and Talk Arena evaluate conversational agents through live, head-to-head speech interactions.

These works aim to close the gap between text-based and spoken dialogue systems, emphasizing conversational quality, adaptation, and user trust.

3. Social Skill Training & Well-Being

Another thread explores LLMs as partners or mentors for social and emotional learning.

Systems such as APAM (AI Partner & AI Mentor) and Rehearsal simulate interpersonal situations like conflict resolution or counseling training.

These models are tested in controlled studies to measure their effects on empathy, self-disclosure, and social skill development.

4. Language Variation, Dialects & Low-Resource NLP

Yang has consistently worked on improving dialectal robustness and linguistic inclusivity in NLP.

Her lab builds benchmarks like VALUE and Multi-VALUE for measuring model performance across English dialects.

She also introduces methods like DADA, which integrate linguistic rules to adapt models for low-resource dialects and domains.

5. Culture, Norms & Societal Impacts of Alignment

This line investigates how LLMs encode and reflect cultural norms and moral values.

Datasets such as NormBank and CultureBank collect situational norms and cultural values across societies.

The CoMPosT project analyzes how cultural caricature appears in AI simulations, while studies on alignment trace how model fine-tuning alters representations of dialect, ideology, and diversity.

6. Online Communities, Social Roles & Supportive Interaction

An early and enduring theme in Yang’s research examines social roles and supportive behavior in online communities.

She models interaction patterns in health forums, Wikipedia discussions, and crowdfunding sites, identifying key roles like seekers, providers, and moderators.

This work investigates how linguistic style and community structure affect self-disclosure, social support, and success in collaborative problem-solving.

7. Methods, Datasets & Evaluation for NLP

Yang frequently pairs social goals with methodological advances.

She co-created ToTTo, a large benchmark for controlled table-to-text generation.

Other projects span discourse-aware summarization, data augmentation techniques for low-data scenarios, and neural architectures such as hierarchical attention networks.

8. Bias, Safety & Reasoning Behaviors in LLMs

With collaborators in HCI and responsible AI, she studies the sociotechnical effects of prompting and reasoning in LLMs.

Her group shows that chain-of-thought prompting can sometimes amplify bias or toxicity in socially sensitive tasks.

They advocate for safer, more culturally grounded prompting strategies that align reasoning with human values.

Teaching, Service & Roles

At Stanford, Yang teaches Human-Centered NLP, NLP for Computational Social Science, and CS224N. She has served on numerous ACL, EMNLP, CHI, and ICWSM committees and is Program Chair for ICLR 2026.

Throughlines

Across all her strands, Yang’s agenda integrates NLP, HCI, and social science to build AI systems that are:

Collaborative — designed for meaningful human-AI interaction;

Equitable — robust across dialects, cultures, and contexts; and

Responsible — empirically grounded in social and ethical considerations.

Her recent efforts—GenUI, GUM, WORKBank, NormBank, and CultureBank—reflect a cohesive research program toward practical, socially responsible AI that understands and supports human communication.