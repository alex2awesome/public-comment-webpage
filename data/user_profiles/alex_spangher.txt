Alex Spangher (USC) — Research Summary

Alex Spangher’s work centers on computational journalism and language technologies for creative, decision-driven writing. While a PhD researcher at USC’s Information Sciences Institute (ISI), he built large, practice-grounded datasets and models to study how journalists plan, source, update, and prioritize information—and used those insights to design AI systems that better support newsroom workflows. A unifying theme is modeling planning and decision-making in communication, which he later formalized under the banner of “emulation learning.”

Core research strands

1) Editing & factual updating in news (“NewsEdits”).
Spangher led NewsEdits, the first public-scale corpus of revision histories for news articles (1.2M articles, 4.6M versions across 22 outlets, 2006–2021). He introduced document-level edit actions (Addition, Deletion, Edit, Refactor) and tasks for predicting revision behavior; the work received an Outstanding Paper recognition at NAACL 2022. He extended this line with NewsEdits 2.0, an edit-intentions schema distinguishing factual vs. stylistic/narrative changes and showed how predicting “fact updates” can drive safer LLM abstention on soon-to-be-stale content.

2) Sourcing & source recommendation.
He constructed a large annotated dataset of informational sources in newswriting and trained strong models for source detection, attribution, and source prediction—a step toward “source recommendation” tools that promote diverse, original sourcing. Follow-on work analyzes mixtures of sources and functional “source schemas” in narratives; this strand has been profiled as part of tools for helping journalists find diverse sources.

3) Planning in creative writing (journalists vs. LLMs).
In Do LLMs Plan Like Human Writers?, Spangher assembled a PressRelease corpus (≈650k news articles linked to ≈250k press releases) to compare newsroom planning behaviors with LLM outputs, revealing systematic gaps in planning and coverage/challenge dynamics; the paper earned an EMNLP 2024 Outstanding Paper Award.

4) Newsworthiness & agenda setting.
He modeled which public documents become news by linking San Francisco legislative proposals, local news articles, and hours of meeting video via probabilistic relational modeling, quantifying coverage rates and predictive factors. This work grounds “story discovery” tools in civic processes.

5) Editorial prioritization and presentation.
A recent preprint introduces NewsHomepages, a dataset of thousands of news site homepages to study layout decisions as signals of editorial prioritization.

6) Agents & end-to-end evaluation.
Spangher co-authored WebDS, a benchmark of 870 real web-based data-science tasks across 29 sites, showing current web agents struggle with grounding and repetitive behaviors—evidence for more process-aware reasoning systems.

Through-line & impact

Across these strands, Spangher blends corpus building with causal, decision-oriented questions about how writers plan, which sources they select, when facts change, and what gets surfaced to audiences. His USC period features collaborations with ISI, Stanford’s Big Local News, and industry, public talks on planning in creative contexts, and multiple paper recognitions (NAACL 2022 Outstanding; EMNLP 2024 Outstanding). Collectively, the work advances newsroom-aligned AI—systems that reason about planning, sourcing, and updating, rather than just text generation.

Selected datasets & tools: NewsEdits / NewsEdits 2.0 (revision + intentions), PressRelease (PR–news linking), Sources (detection/attribution/prediction), Newsworthiness (policy–news–video linkage), NewsHomepages (layout signals), and WebDS (agentic data-science workflows).