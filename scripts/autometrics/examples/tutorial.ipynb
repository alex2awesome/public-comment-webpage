{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3315d3f4",
   "metadata": {},
   "source": [
    "# Super Simple Autometrics Tutorial\n",
    "=================================\n",
    "\n",
    "This tutorial shows the absolute basics of using autometrics.\n",
    "Just load a dataset, run the pipeline, and get your metrics!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c772926e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202b54a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "/Users/spangher/miniconda3/lib/python3.12/site-packages/pyemd/__init__.py:74: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from .emd import emd, emd_with_flow, emd_samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Autometrics] No GPU detected - using BM25 + LLMRec pipeline for CPU-optimized performance\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dspy\n",
    "from autometrics.autometrics import Autometrics\n",
    "from autometrics.dataset.datasets.simplification.simplification import SimpDA\n",
    "from autometrics.aggregator.regression.ElasticNet import ElasticNet\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = open('/Users/spangher/.openai-reglab-project-key.txt').read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d47dbd7b-a692-4b78-9f75-7d3ab87eb9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset: SimpDA, Target Columns: ['fluency', 'meaning', 'simplicity'], Ignore Columns: ['id', 'original', 'simple', 'system', 'ref1', 'ref2', 'ref3', 'ref4', 'ref5', 'ref6', 'ref7', 'ref8', 'ref9', 'ref10'], Metric Columns: ['LENS', 'SARI_P', 'SARI_F', 'FKGL', 'BERTScoreP_roberta-large', 'BERTScoreR_roberta-large', 'BERTScoreF_roberta-large', 'BLEU', 'METEOR', 'ROUGE-1-p', 'ROUGE-2-p', 'ROUGE-L-p', 'ROUGE-Lsum-p', 'ROUGE-1-r', 'ROUGE-2-r', 'ROUGE-L-r', 'ROUGE-Lsum-r', 'ROUGE-1-f1', 'ROUGE-2-f1', 'ROUGE-L-f1', 'ROUGE-Lsum-f1', 'distinct_1', 'distinct_2', 'distinct_3', 'distinct_4', 'Perplexity_gpt2-large', 'Autometrics_Regression_simplicity']\n",
       "   id                                           original  \\\n",
       "0   0  a bastion on the eastern approaches was built ...   \n",
       "1   0  a bastion on the eastern approaches was built ...   \n",
       "2   0  a bastion on the eastern approaches was built ...   \n",
       "3   2  a few animals have chromatic response, changin...   \n",
       "4   2  a few animals have chromatic response, changin...   \n",
       "\n",
       "                                              simple   fluency   meaning  \\\n",
       "0     a bastion on the eastern side was built later.  0.415042  1.102220   \n",
       "1  a bastion on the east organizing was built later. -0.529806 -0.734364   \n",
       "2  a bastion in the east nears was built at a lat...  0.116173 -0.308315   \n",
       "3  a few animals have chromatic response, changin...  0.285011  0.853444   \n",
       "4  animals have a response, changing color, eithe... -0.890238 -0.880717   \n",
       "\n",
       "   simplicity      system                                               ref1  \\\n",
       "0    1.351604      ACCESS  a fort on the eastern access road was built la...   \n",
       "1   -0.873206  DMASS-DCSS  a fort on the eastern access road was built la...   \n",
       "2   -0.471797   SBMT-SARI  a fort on the eastern access road was built la...   \n",
       "3   -0.280680      ACCESS  some animals change color in different environ...   \n",
       "4   -0.684491      Hybrid  some animals change color in different environ...   \n",
       "\n",
       "                                                ref2  \\\n",
       "0  a fortification on the eastern approaches was ...   \n",
       "1  a fortification on the eastern approaches was ...   \n",
       "2  a fortification on the eastern approaches was ...   \n",
       "3  a few animals have a chromatic response, which...   \n",
       "4  a few animals have a chromatic response, which...   \n",
       "\n",
       "                                                ref3  ... ROUGE-1-f1  \\\n",
       "0             a support on the east was built later.  ...   1.000000   \n",
       "1             a support on the east was built later.  ...   0.823529   \n",
       "2             a support on the east was built later.  ...   0.600000   \n",
       "3  a few animals have chromatic response. they ca...  ...   0.625000   \n",
       "4  a few animals have chromatic response. they ca...  ...   0.400000   \n",
       "\n",
       "  ROUGE-2-f1 ROUGE-L-f1 ROUGE-Lsum-f1 distinct_1 distinct_2 distinct_3  \\\n",
       "0   1.000000   1.000000      1.000000   1.000000        1.0        1.0   \n",
       "1   0.777778   0.875000      0.823529   1.000000        1.0        1.0   \n",
       "2   0.500000   0.750000      0.600000   0.923077        1.0        1.0   \n",
       "3   0.740741   0.548387      0.625000   0.852941        1.0        1.0   \n",
       "4   0.818182   0.357143      0.400000   0.875000        1.0        1.0   \n",
       "\n",
       "   distinct_4  Perplexity_gpt2-large  Autometrics_Regression_simplicity  \n",
       "0         1.0              90.439667                           0.813112  \n",
       "1         1.0             512.057373                          -0.111166  \n",
       "2         1.0             127.784607                          -0.640870  \n",
       "3         1.0              51.844463                          -0.039386  \n",
       "4         1.0             198.687134                          -1.012662  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dafd1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: SimpDA\n",
      "Size: 434 examples\n",
      "Target measure: simplicity\n",
      "LLMs configured!\n"
     ]
    }
   ],
   "source": [
    "# Load the SimpDA dataset (text simplification)\n",
    "dataset = SimpDA(path='../autometrics/dataset/datasets/simplification/simpda.csv')\n",
    "target_measure = \"simplicity\"  # The human score column we want to predict\n",
    "\n",
    "print(f\"Dataset: {dataset.get_name()}\")\n",
    "print(f\"Size: {len(dataset.get_dataframe())} examples\")\n",
    "print(f\"Target measure: {target_measure}\")\n",
    "\n",
    "## Cell 3: Configure LLMs\n",
    "# Use GPT-4o-mini for both generation and judging\n",
    "generator_llm = dspy.LM(\"openai/gpt-4o-mini\")\n",
    "judge_llm = dspy.LM(\"openai/gpt-4o-mini\")\n",
    "\n",
    "print(\"LLMs configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d124b9",
   "metadata": {},
   "source": [
    "## Autometrics Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d56e08aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super simple configuration:\n",
    "# - Generate 1 metric using LLM judge\n",
    "# - Retrieve 10 metrics from the bank\n",
    "# - Select top 5 using ElasticNet regression\n",
    "autometrics = Autometrics(\n",
    "    metric_generation_configs={\n",
    "        \"llm_judge\": {\"metrics_per_trial\": 1}  # Just generate 1 metric\n",
    "    },\n",
    "    regression_strategy=ElasticNet,  # Use ElasticNet instead of default Lasso\n",
    "    seed=42,  # For reproducibility\n",
    "    generated_metrics_dir=\"tutorial_metrics\"  # Unique directory for this tutorial\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f3a58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running autometrics pipeline...\n",
      "This will:\n",
      "1. Generate 1 LLM judge metric\n",
      "2. Retrieve 10 relevant metrics from the bank\n",
      "3. Evaluate all metrics on your dataset\n",
      "4. Select top 5 using ElasticNet regression\n",
      "5. Create a final aggregated metric\n",
      "[Autometrics] Starting pipeline for SimpDA - simplicity\n",
      "[Autometrics] Configuration: retrieve=10, regress=5, regenerate=False\n",
      "\n",
      "[Autometrics] Step 1: Generating/Loading Metrics\n",
      "[Autometrics] Generating 1 metrics using llm_judge...\n",
      "Initializing BM25 recommender with index path: /Users/spangher/Library/Application Support/autometrics/bm25_all_metrics\n",
      "Building BM25 index in /Users/spangher/Library/Application Support/autometrics/bm25_all_metrics/index for 48 metrics â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:53:54,496 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:208) - Setting log level to INFO\n",
      "2025-11-17 17:53:54,497 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:211) - ============ Loading Index Configuration ============\n",
      "2025-11-17 17:53:54,497 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:212) - AbstractIndexer settings:\n",
      "2025-11-17 17:53:54,505 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:213) -  + DocumentCollection path: /Users/spangher/Library/Application Support/autometrics/bm25_all_metrics/collection\n",
      "2025-11-17 17:53:54,506 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:214) -  + CollectionClass: JsonCollection\n",
      "2025-11-17 17:53:54,506 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:215) -  + Index path: /Users/spangher/Library/Application Support/autometrics/bm25_all_metrics/index\n",
      "2025-11-17 17:53:54,506 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:216) -  + Threads: 1\n",
      "2025-11-17 17:53:54,506 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:217) -  + Optimize (merge segments)? false\n",
      "2025-11-17 17:53:54,522 INFO  [main] index.IndexCollection (IndexCollection.java:237) - Using DefaultEnglishAnalyzer\n",
      "2025-11-17 17:53:54,523 INFO  [main] index.IndexCollection (IndexCollection.java:238) - Stemmer: porter\n",
      "2025-11-17 17:53:54,523 INFO  [main] index.IndexCollection (IndexCollection.java:239) - Keep stopwords? false\n",
      "2025-11-17 17:53:54,523 INFO  [main] index.IndexCollection (IndexCollection.java:240) - Stopwords file: null\n",
      "2025-11-17 17:53:54,583 INFO  [main] index.IndexCollection (IndexCollection.java:188) - IndexCollection settings:\n",
      "2025-11-17 17:53:54,583 INFO  [main] index.IndexCollection (IndexCollection.java:189) -  + Generator: DefaultLuceneDocumentGenerator\n",
      "2025-11-17 17:53:54,583 INFO  [main] index.IndexCollection (IndexCollection.java:190) -  + Language: en\n",
      "2025-11-17 17:53:54,583 INFO  [main] index.IndexCollection (IndexCollection.java:191) -  + Stemmer: porter\n",
      "2025-11-17 17:53:54,583 INFO  [main] index.IndexCollection (IndexCollection.java:192) -  + Keep stopwords? false\n",
      "2025-11-17 17:53:54,583 INFO  [main] index.IndexCollection (IndexCollection.java:193) -  + Stopwords: null\n",
      "2025-11-17 17:53:54,584 INFO  [main] index.IndexCollection (IndexCollection.java:194) -  + Store positions? true\n",
      "2025-11-17 17:53:54,584 INFO  [main] index.IndexCollection (IndexCollection.java:195) -  + Store docvectors? true\n",
      "2025-11-17 17:53:54,584 INFO  [main] index.IndexCollection (IndexCollection.java:196) -  + Store document \"contents\" field? false\n",
      "2025-11-17 17:53:54,584 INFO  [main] index.IndexCollection (IndexCollection.java:197) -  + Store document \"raw\" field? true\n",
      "2025-11-17 17:53:54,584 INFO  [main] index.IndexCollection (IndexCollection.java:198) -  + Additional fields to index: []\n",
      "2025-11-17 17:53:54,584 INFO  [main] index.IndexCollection (IndexCollection.java:199) -  + Whitelist: null\n",
      "2025-11-17 17:53:54,584 INFO  [main] index.IndexCollection (IndexCollection.java:200) -  + Pretokenized?: false\n",
      "2025-11-17 17:53:54,584 INFO  [main] index.IndexCollection (IndexCollection.java:201) -  + Codec: Lucene99\n",
      "2025-11-17 17:53:54,584 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:241) - ============ Indexing Collection ============\n",
      "2025-11-17 17:53:54,586 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:250) - Thread pool with 1 threads initialized.\n",
      "2025-11-17 17:53:54,586 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:251) - 1 file found in /Users/spangher/Library/Application Support/autometrics/bm25_all_metrics/collection\n",
      "2025-11-17 17:53:54,586 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:252) - Starting to index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nov 17, 2025 5:53:54 PM org.apache.lucene.store.MemorySegmentIndexInputProvider <init>\n",
      "INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:53:54,829 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:292) - Indexing Complete! 48 documents indexed\n",
      "2025-11-17 17:53:54,830 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:293) - ============ Final Counter Values ============\n",
      "2025-11-17 17:53:54,830 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:294) - indexed:               48\n",
      "2025-11-17 17:53:54,830 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:295) - unindexable:            0\n",
      "2025-11-17 17:53:54,830 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:296) - empty:                  0\n",
      "2025-11-17 17:53:54,830 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:297) - skipped:                0\n",
      "2025-11-17 17:53:54,830 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:298) - errors:                 0\n",
      "2025-11-17 17:53:54,833 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:301) - Total 48 documents indexed in 00:00:00\n",
      "BM25 recommender loaded successfully\n",
      "[Autometrics] Saved 1 metrics for llm_judge\n",
      "[Autometrics] Generated/Loaded 1 metrics\n",
      "\n",
      "[Autometrics] Step 2: Loading Metric Bank\n",
      "[Autometrics] Loaded 48 metrics in bank\n",
      "\n",
      "[Autometrics]  Merging Generated Metrics with Metric Bank\n",
      "[Autometrics] Merged 1 unique generated metrics with 48 existing metrics\n",
      "[Autometrics] Configuring retriever...\n",
      "[Autometrics] Validating and adjusting retriever config for SimpDA with 49 metrics to retrieve 10 metrics\n",
      "[<class 'autometrics.metrics.reference_based.BLEU.BLEU'>, <class 'autometrics.metrics.reference_based.CHRF.CHRF'>, <class 'autometrics.metrics.reference_based.TER.TER'>, <class 'autometrics.metrics.reference_based.GLEU.GLEU'>, <class 'autometrics.metrics.reference_based.SARI.SARI'>, <class 'autometrics.metrics.reference_based.BERTScore.BERTScore'>, <class 'autometrics.metrics.reference_based.ROUGE.ROUGE'>, <class 'autometrics.metrics.reference_based.MOVERScore.MOVERScore'>, <class 'autometrics.metrics.reference_based.BARTScore.BARTScore'>, <class 'autometrics.metrics.reference_based.UniEvalDialogue.UniEvalDialogue'>, <class 'autometrics.metrics.reference_based.UniEvalSum.UniEvalSum'>, <class 'autometrics.metrics.reference_based.CIDEr.CIDEr'>, <class 'autometrics.metrics.reference_based.METEOR.METEOR'>, <class 'autometrics.metrics.reference_based.BLEURT.BLEURT'>, <class 'autometrics.metrics.reference_based.StringSimilarity.LevenshteinDistance'>, <class 'autometrics.metrics.reference_based.StringSimilarity.LevenshteinRatio'>, <class 'autometrics.metrics.reference_based.StringSimilarity.HammingDistance'>, <class 'autometrics.metrics.reference_based.StringSimilarity.JaroSimilarity'>, <class 'autometrics.metrics.reference_based.StringSimilarity.JaroWinklerSimilarity'>, <class 'autometrics.metrics.reference_based.StringSimilarity.JaccardDistance'>, <class 'autometrics.metrics.reference_based.ParaScore.ParaScore'>, <class 'autometrics.metrics.reference_based.YiSi.YiSi'>, <class 'autometrics.metrics.reference_based.MAUVE.MAUVE'>, <class 'autometrics.metrics.reference_based.PseudoPARENT.PseudoPARENT'>, <class 'autometrics.metrics.reference_based.NIST.NIST'>, <class 'autometrics.metrics.reference_based.IBLEU.IBLEU'>, <class 'autometrics.metrics.reference_based.UpdateROUGE.UpdateROUGE'>, <class 'autometrics.metrics.reference_based.LENS.LENS'>, <class 'autometrics.metrics.reference_based.CharCut.CharCut'>, <class 'autometrics.metrics.reference_based.InfoLM.InfoLM'>, <class 'autometrics.metrics.reference_free.FKGL.FKGL'>, <class 'autometrics.metrics.reference_free.UniEvalFact.UniEvalFact'>, <class 'autometrics.metrics.reference_free.Perplexity.Perplexity'>, <class 'autometrics.metrics.reference_free.ParaScoreFree.ParaScoreFree'>, <class 'autometrics.metrics.reference_free.INFORMRewardModel.INFORMRewardModel'>, <class 'autometrics.metrics.reference_free.PRMRewardModel.MathProcessRewardModel'>, <class 'autometrics.metrics.reference_free.SummaQA.SummaQA'>, <class 'autometrics.metrics.reference_free.DistinctNGram.DistinctNGram'>, <class 'autometrics.metrics.reference_free.FastTextToxicity.FastTextToxicity'>, <class 'autometrics.metrics.reference_free.FastTextNSFW.FastTextNSFW'>, <class 'autometrics.metrics.reference_free.FastTextEducationalValue.FastTextEducationalValue'>, <class 'autometrics.metrics.reference_free.SelfBLEU.SelfBLEU'>, <class 'autometrics.metrics.reference_free.FactCC.FactCC'>, <class 'autometrics.metrics.reference_free.Toxicity.Toxicity'>, <class 'autometrics.metrics.reference_free.Sentiment.Sentiment'>, <class 'autometrics.metrics.reference_free.GRMRewardModel.GRMRewardModel'>, <class 'autometrics.metrics.reference_free.LENS_SALSA.LENS_SALSA'>, <class 'autometrics.metrics.reference_free.LDLRewardModel.LDLRewardModel'>, <class 'SimpDA_simplicity_llm_judge_seed42_metric01.Clarity_of_Expression_gpt_4o_mini_LLMJudge'>]\n",
      "['BARTScore', 'BERTScore', 'BLEU', 'BLEURT', 'CHRF', 'CIDEr', 'CharCut', 'Clarity_of_Expression_gpt_4o_mini_LLMJudge', 'DistinctNGram', 'FKGL', 'FactCC', 'FastTextEducationalValue', 'FastTextNSFW', 'FastTextToxicity', 'GLEU', 'GRMRewardModel', 'HammingDistance', 'IBLEU', 'INFORMRewardModel', 'InfoLM', 'JaccardDistance', 'JaroSimilarity', 'JaroWinklerSimilarity', 'LDLRewardModel', 'LENS', 'LENS_SALSA', 'LevenshteinDistance', 'LevenshteinRatio', 'MAUVE', 'METEOR', 'MOVERScore', 'MathProcessRewardModel', 'NIST', 'ParaScore', 'ParaScoreFree', 'Perplexity', 'PseudoPARENT', 'ROUGE', 'SARI', 'SelfBLEU', 'Sentiment', 'SummaQA', 'TER', 'Toxicity', 'UniEvalDialogue', 'UniEvalFact', 'UniEvalSum', 'UpdateROUGE', 'YiSi']\n",
      "b'BARTScoreBERTScoreBLEUBLEURTCHRFCIDErCharCutClarity_of_Expression_gpt_4o_mini_LLMJudgeDistinctNGramFKGLFactCCFastTextEducationalValueFastTextNSFWFastTextToxicityGLEUGRMRewardModelHammingDistanceIBLEUINFORMRewardModelInfoLMJaccardDistanceJaroSimilarityJaroWinklerSimilarityLDLRewardModelLENSLENS_SALSALevenshteinDistanceLevenshteinRatioMAUVEMETEORMOVERScoreMathProcessRewardModelNISTParaScoreParaScoreFreePerplexityPseudoPARENTROUGESARISelfBLEUSentimentSummaQATERToxicityUniEvalDialogueUniEvalFactUniEvalSumUpdateROUGEYiSi'\n",
      "5db6f1da\n",
      "[Autometrics] Adjusting final top_k from 30 to 10 to match num_to_retrieve\n",
      "[Autometrics] Configuring regression strategy...\n",
      "\n",
      "[Autometrics] Step 3: Retrieving Top 10 Metrics\n",
      "[Autometrics] Retrieving top 10 metrics from 49 available metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nov 17, 2025 5:53:54 PM org.apache.lucene.store.MemorySegmentIndexInputProvider <init>\n",
      "INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false\n",
      "/Users/spangher/Projects/stanford-research/rfi-research/regulations-demo/scripts/autometrics/examples/tutorial_metrics/generated_metrics/SimpDA/simplicity/seed_42/llm_judge/SimpDA_simplicity_llm_judge_seed42_metric01.py:10: SyntaxWarning: invalid escape sequence '\\h'\n",
      "  \"\"\"---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building BM25 index in /Users/spangher/Library/Application Support/autometrics/bm25_SimpDA_5db6f1da_card/index for 49 metrics â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:53:56,143 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:208) - Setting log level to INFO\n",
      "2025-11-17 17:53:56,144 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:211) - ============ Loading Index Configuration ============\n",
      "2025-11-17 17:53:56,144 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:212) - AbstractIndexer settings:\n",
      "2025-11-17 17:53:56,153 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:213) -  + DocumentCollection path: /Users/spangher/Library/Application Support/autometrics/bm25_SimpDA_5db6f1da_card/collection\n",
      "2025-11-17 17:53:56,153 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:214) -  + CollectionClass: JsonCollection\n",
      "2025-11-17 17:53:56,154 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:215) -  + Index path: /Users/spangher/Library/Application Support/autometrics/bm25_SimpDA_5db6f1da_card/index\n",
      "2025-11-17 17:53:56,154 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:216) -  + Threads: 1\n",
      "2025-11-17 17:53:56,154 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:217) -  + Optimize (merge segments)? false\n",
      "2025-11-17 17:53:56,167 INFO  [main] index.IndexCollection (IndexCollection.java:237) - Using DefaultEnglishAnalyzer\n",
      "2025-11-17 17:53:56,167 INFO  [main] index.IndexCollection (IndexCollection.java:238) - Stemmer: porter\n",
      "2025-11-17 17:53:56,167 INFO  [main] index.IndexCollection (IndexCollection.java:239) - Keep stopwords? false\n",
      "2025-11-17 17:53:56,167 INFO  [main] index.IndexCollection (IndexCollection.java:240) - Stopwords file: null\n",
      "2025-11-17 17:53:56,217 INFO  [main] index.IndexCollection (IndexCollection.java:188) - IndexCollection settings:\n",
      "2025-11-17 17:53:56,217 INFO  [main] index.IndexCollection (IndexCollection.java:189) -  + Generator: DefaultLuceneDocumentGenerator\n",
      "2025-11-17 17:53:56,217 INFO  [main] index.IndexCollection (IndexCollection.java:190) -  + Language: en\n",
      "2025-11-17 17:53:56,217 INFO  [main] index.IndexCollection (IndexCollection.java:191) -  + Stemmer: porter\n",
      "2025-11-17 17:53:56,217 INFO  [main] index.IndexCollection (IndexCollection.java:192) -  + Keep stopwords? false\n",
      "2025-11-17 17:53:56,217 INFO  [main] index.IndexCollection (IndexCollection.java:193) -  + Stopwords: null\n",
      "2025-11-17 17:53:56,218 INFO  [main] index.IndexCollection (IndexCollection.java:194) -  + Store positions? true\n",
      "2025-11-17 17:53:56,218 INFO  [main] index.IndexCollection (IndexCollection.java:195) -  + Store docvectors? true\n",
      "2025-11-17 17:53:56,218 INFO  [main] index.IndexCollection (IndexCollection.java:196) -  + Store document \"contents\" field? false\n",
      "2025-11-17 17:53:56,218 INFO  [main] index.IndexCollection (IndexCollection.java:197) -  + Store document \"raw\" field? true\n",
      "2025-11-17 17:53:56,218 INFO  [main] index.IndexCollection (IndexCollection.java:198) -  + Additional fields to index: []\n",
      "2025-11-17 17:53:56,218 INFO  [main] index.IndexCollection (IndexCollection.java:199) -  + Whitelist: null\n",
      "2025-11-17 17:53:56,218 INFO  [main] index.IndexCollection (IndexCollection.java:200) -  + Pretokenized?: false\n",
      "2025-11-17 17:53:56,218 INFO  [main] index.IndexCollection (IndexCollection.java:201) -  + Codec: Lucene99\n",
      "2025-11-17 17:53:56,218 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:241) - ============ Indexing Collection ============\n",
      "2025-11-17 17:53:56,219 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:250) - Thread pool with 1 threads initialized.\n",
      "2025-11-17 17:53:56,220 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:251) - 1 file found in /Users/spangher/Library/Application Support/autometrics/bm25_SimpDA_5db6f1da_card/collection\n",
      "2025-11-17 17:53:56,220 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:252) - Starting to index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nov 17, 2025 5:53:56 PM org.apache.lucene.store.MemorySegmentIndexInputProvider <init>\n",
      "INFO: Using MemorySegmentIndexInput with Java 21; to disable start with -Dorg.apache.lucene.store.MMapDirectory.enableMemorySegments=false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:53:56,440 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:292) - Indexing Complete! 49 documents indexed\n",
      "2025-11-17 17:53:56,441 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:293) - ============ Final Counter Values ============\n",
      "2025-11-17 17:53:56,441 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:294) - indexed:               49\n",
      "2025-11-17 17:53:56,441 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:295) - unindexable:            0\n",
      "2025-11-17 17:53:56,441 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:296) - empty:                  0\n",
      "2025-11-17 17:53:56,441 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:297) - skipped:                0\n",
      "2025-11-17 17:53:56,441 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:298) - errors:                 0\n",
      "2025-11-17 17:53:56,444 INFO  [main] index.AbstractIndexer (AbstractIndexer.java:301) - Total 49 documents indexed in 00:00:00\n",
      "Starting iterative recommendation: requesting 10 metrics from 49 available\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Requesting 10 metrics from 49 remaining metrics\n",
      "Planning recommendation strategy for 49 metrics, k=10\n",
      "Using max_input_tokens for gpt-4o-mini: 128000\n",
      "Model: openai/gpt-4o-mini\n",
      "Max context: 128000\n",
      "Available for prompt: 117808\n",
      "Estimated average tokens per metric documentation: 1338\n",
      "Binary search for max batch size (available: 117808 tokens):\n",
      "    Token estimation: base=253, docs=43485, total=43738\n",
      "  25 metrics OK (43738 tokens)\n",
      "    Token estimation: base=253, docs=64358, total=64611\n",
      "  37 metrics OK (64610 tokens)\n",
      "    Token estimation: base=253, docs=74794, total=75047\n",
      "  43 metrics OK (75047 tokens)\n",
      "    Token estimation: base=253, docs=80012, total=80265\n",
      "  46 metrics OK (80265 tokens)\n",
      "    Token estimation: base=253, docs=83491, total=83744\n",
      "  48 metrics OK (83744 tokens)\n",
      "    Token estimation: base=253, docs=85231, total=85484\n",
      "  49 metrics OK (85483 tokens)\n",
      "Final max metrics per batch: 49\n",
      "All metrics fit in one batch, recommending directly\n",
      "  _recommend_batch: 49 metrics -> requesting 10 recommendations\n",
      "  _recommend_batch: LLM returned 10 recommendations\n",
      "Raw ranking received: ['Clarity_of_Expression_gpt_4o_mini', 'LENS', 'SARI', 'FKGL', 'BERTScore', 'BLEU', 'METEOR', 'ROUGE', 'DistinctNGram', 'PERPLEXITY']\n",
      "After metric_name_to_class: 9 valid conversions\n",
      "After filtering and deduplication: 9 final metrics\n",
      "Returning 9 metrics (requested 10)\n",
      "Iteration 1: LLM returned 9 metrics (requested 10)\n",
      "Total metrics so far: 9/10 (90.0%)\n",
      "Quota filled to 90.0%, stopping iterations\n",
      "\n",
      "Final result: 9 unique metrics (requested 10)\n",
      "[Autometrics] Retrieved 9 metrics\n",
      "  1. LENS\n",
      "  2. SARI\n",
      "  3. FKGL\n",
      "  4. BERTScore\n",
      "  5. BLEU\n",
      "  6. METEOR\n",
      "  7. ROUGE\n",
      "  8. DistinctNGram\n",
      "  9. Perplexity\n",
      "[Autometrics] Retrieved 9 metrics\n",
      "\n",
      "[Autometrics] Step 4: Evaluating 9 Metrics on Dataset (0 priors + 9 retrieved)\n",
      "[Autometrics] Building 9 metrics with GPU allocation...\n",
      "[MetricBank] BERTScore model has no device info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spangher/Projects/stanford-research/rfi-research/regulations-demo/scripts/autometrics/autometrics/metrics/utils/gpu_allocation.py:292: UserWarning: CUDA is not available â€“ forcing all metrics to run on CPU.\n",
      "  warnings.warn(\"CUDA is not available â€“ forcing all metrics to run on CPU.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9442e2379f2d4258b7461c58fa8f3075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d18e47d7774f5395e2e6563481f8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f771ee9d28d84af59ad4c67f13fd9ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51bc63a91dde485586125b89fe209219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a497d4de5ee469e803acba1d02ee20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecec94e1704a448aaecc6dcc18705448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cfa90cfd1a4a778e1bd48c88347ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MetricBank] Perplexity model device: cpu\n",
      "[Autometrics] Built 9 valid metrics\n",
      "[Autometrics] Evaluating 9 regular metrics using parallel execution...\n",
      "[Parallel] LENS - checking device before predict...\n",
      "[Parallel] SARI - checking device before predict...\n",
      "[Parallel] FKGL - checking device before predict...\n",
      "[Parallel] BERTScore_roberta-large - checking device before predict...\n",
      "[Parallel] BERTScore_roberta-large model has no device info\n",
      "[Parallel] BLEU - checking device before predict...\n",
      "[Parallel] METEOR - checking device before predict...\n",
      "[Parallel] ROUGE - checking device before predict...\n",
      "[Parallel] DistinctNGram - checking device before predict...\n",
      "[Parallel] Perplexity_gpt2-large - checking device before predict...\n",
      "[Parallel] Perplexity_gpt2-large model device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a5db7721e24cc6b903ef5ff17e98a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ecbb7c830f40e582e529e0045c2908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b949a22579a4c18b5deacdbdc62a195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "checkpoints/model.ckpt:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da33d83a5a174f39898a187492dcf3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b07ba09ffb49e9a317acdf33b26d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636b3207c66945a8b297dfe6b51b50cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hparams.yaml:   0%|          | 0.00/705 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356cfbbcaa5341d59bc38df80a40cc9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Groups:   0%|                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b76496223b741ab8fbf165cb5a19efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âœ“ SARI computed successfully (parallel)\n",
      "    âœ“ BLEU computed successfully (parallel)\n",
      "    âœ“ METEOR computed successfully (parallel)\n",
      "    âœ“ DistinctNGram computed successfully (parallel)\n",
      "    âœ“ FKGL computed successfully (parallel)\n",
      "    âœ“ ROUGE computed successfully (parallel)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2d16a7eebd48d3b5c3e8d5562a1e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aba6a40475e4d7bb0191745bb8b9cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677054e67f4d480f96dbfd7b74dd2e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LENS with topk=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/spangher/miniconda3/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:188: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "\n",
      "2025-11-17 17:56:58,647 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: True (mps), used: False\n",
      "\n",
      "2025-11-17 17:56:58,719 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores\n",
      "\n",
      "2025-11-17 17:56:58,720 - pytorch_lightning.utilities.rank_zero - INFO - IPU available: False, using: 0 IPUs\n",
      "\n",
      "2025-11-17 17:56:58,721 - pytorch_lightning.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs\n",
      "/Users/spangher/miniconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "Predicting DataLoader 0:   4%|â–ˆâ–ˆâ–Ž                                                 | 12/272 [00:23<08:19,  1.92s/it]\n",
      "\n",
      "\n",
      "Groups: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:31<00:00, 91.77s/it]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âœ“ Perplexity_gpt2-large computed successfully (parallel)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:  10%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰                                               | 26/272 [00:53<08:29,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âœ“ BERTScore_roberta-large computed successfully (parallel)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 272/272 [07:20<00:00,  1.62s/it]\n",
      "/Users/spangher/Projects/stanford-research/rfi-research/regulations-demo/scripts/autometrics/autometrics/util/report_card.py:777: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  template = \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âœ“ LENS computed successfully (parallel)\n",
      "[Autometrics] Aggregating results back to original dataset...\n",
      "    âœ“ LENS aggregated successfully\n",
      "    âœ“ SARI aggregated successfully\n",
      "    âœ“ FKGL aggregated successfully\n",
      "    âœ“ BERTScore_roberta-large aggregated successfully\n",
      "    âœ“ BLEU aggregated successfully\n",
      "    âœ“ METEOR aggregated successfully\n",
      "    âœ“ ROUGE aggregated successfully\n",
      "    âœ“ DistinctNGram aggregated successfully\n",
      "    âœ“ Perplexity_gpt2-large aggregated successfully\n",
      "[Autometrics] Parallel evaluation complete. Dataset now has 9 metrics\n",
      "[Autometrics] Successfully evaluated 9 metrics, 0 failed\n",
      "\n",
      "[Autometrics] Step 5: Regression Analysis (Selecting Top 5 via ElasticNet)\n",
      "[Autometrics] Running regression to select top 5 metrics from 9 candidates...\n",
      "  Fitting regression on all metrics to identify importance...\n",
      "  Metric importance scores:\n",
      "    1. LENS: 0.3799\n",
      "    2. BERTScoreP_roberta-large: 0.1846\n",
      "    3. BLEU: 0.0802\n",
      "    4. ROUGE-L-p: -0.0473\n",
      "    5. Perplexity_gpt2-large: 0.0437\n",
      "    6. ROUGE-1-f1: -0.0326\n",
      "    7. SARI_F: 0.0280\n",
      "    8. ROUGE-Lsum-f1: -0.0256\n",
      "    9. distinct_4: 0.0250\n",
      "    10. distinct_2: -0.0237\n",
      "    11. SARI_P: 0.0183\n",
      "    12. METEOR: -0.0089\n",
      "    13. FKGL: 0.0000\n",
      "    14. BERTScoreR_roberta-large: -0.0000\n",
      "    15. BERTScoreF_roberta-large: -0.0000\n",
      "    16. ROUGE-1-p: -0.0000\n",
      "    17. ROUGE-2-p: 0.0000\n",
      "    18. ROUGE-Lsum-p: 0.0000\n",
      "    19. ROUGE-1-r: 0.0000\n",
      "    20. ROUGE-2-r: 0.0000\n",
      "    21. ROUGE-L-r: -0.0000\n",
      "    22. ROUGE-Lsum-r: -0.0000\n",
      "    23. ROUGE-2-f1: -0.0000\n",
      "    24. ROUGE-L-f1: -0.0000\n",
      "    25. distinct_1: -0.0000\n",
      "    26. distinct_3: 0.0000\n",
      "  Selected top 5 metrics: ['LENS', 'BERTScore_roberta-large', 'BLEU', 'ROUGE', 'Perplexity_gpt2-large']\n",
      "  Creating final regression metric with top-N metrics...\n",
      "[Autometrics] Found top 5 metrics.\n",
      "[Autometrics] Top metrics: ['LENS', 'BERTScore_roberta-large', 'BLEU', 'ROUGE', 'Perplexity_gpt2-large']\n",
      "\n",
      "[Autometrics] Step 6: Generating Report Card\n",
      "[Autometrics] Report card HTML generated at artifacts/report_SimpDA_simplicity_42.html\n",
      "\n",
      "[Autometrics] Pipeline Complete!\n",
      "Pipeline complete! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "print(\"Running autometrics pipeline...\")\n",
    "print(\"This will:\")\n",
    "print(\"1. Generate 1 LLM judge metric\")\n",
    "print(\"2. Retrieve 10 relevant metrics from the bank\")\n",
    "print(\"3. Evaluate all metrics on your dataset\")\n",
    "print(\"4. Select top 5 using ElasticNet regression\")\n",
    "print(\"5. Create a final aggregated metric\")\n",
    "\n",
    "results = autometrics.run(\n",
    "    dataset=dataset,\n",
    "    target_measure=target_measure,\n",
    "    generator_llm=generator_llm,\n",
    "    judge_llm=judge_llm,\n",
    "    num_to_retrieve=10,  # Retrieve 10 metrics\n",
    "    num_to_regress=5     # Select top 5\n",
    ")\n",
    "\n",
    "print(\"Pipeline complete! ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f2b91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RESULTS\n",
      "==================================================\n",
      "\n",
      "Generated metrics: 1\n",
      "  1. Clarity_of_Expression_gpt_4o_mini_LLMJudge\n",
      "\n",
      "Retrieved metrics: 9\n",
      "  1. LENS\n",
      "  2. SARI\n",
      "  3. FKGL\n",
      "\n",
      "Top selected metrics: 5\n",
      "  1. LENS\n",
      "  2. BERTScore_roberta-large\n",
      "  3. BLEU\n",
      "  4. ROUGE\n",
      "  5. Perplexity_gpt2-large\n",
      "\n",
      "Final regression metric: Autometrics_Regression_simplicity\n",
      "Description: Regression aggregator for simplicity using top 5 metrics\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nGenerated metrics: {len(results['all_generated_metrics'])}\")\n",
    "for i, metric in enumerate(results['all_generated_metrics']):\n",
    "    print(f\"  {i+1}. {metric.__name__}\")\n",
    "\n",
    "print(f\"\\nRetrieved metrics: {len(results['retrieved_metrics'])}\")\n",
    "for i, metric in enumerate(results['retrieved_metrics'][:3]):  # Show first 3\n",
    "    print(f\"  {i+1}. {metric.__name__}\")\n",
    "\n",
    "print(f\"\\nTop selected metrics: {len(results['top_metrics'])}\")\n",
    "for i, metric in enumerate(results['top_metrics']):\n",
    "    print(f\"  {i+1}. {metric.get_name()}\")\n",
    "\n",
    "print(f\"\\nFinal regression metric: {results['regression_metric'].get_name()}\")\n",
    "print(f\"Description: {results['regression_metric'].get_description()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b297b57",
   "metadata": {},
   "source": [
    "## Use Your Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b4a5d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "USING YOUR METRICS\n",
      "==================================================\n",
      "\n",
      "Predicted vs Human scores for first 5 examples:\n",
      "Example | Predicted | Human | Pred Rank | Human Rank\n",
      "-------------------------------------------------------\n",
      "  1     | 0.813    | 1.352 |         1 |          1\n",
      "  2     | -0.111    | -0.873 |         3 |          5\n",
      "  3     | -0.641    | -0.472 |         4 |          3\n",
      "  4     | -0.039    | -0.281 |         2 |          2\n",
      "  5     | -1.013    | -0.684 |         5 |          4\n",
      "\n",
      "Correlation with human scores: 0.780 (p=0.000)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"USING YOUR METRICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get predictions from your final metric\n",
    "final_scores = results['regression_metric'].predict(dataset)\n",
    "human_scores = dataset.get_dataframe()[target_measure]\n",
    "\n",
    "print(f\"\\nPredicted vs Human scores for first 5 examples:\")\n",
    "print(\"Example | Predicted | Human | Pred Rank | Human Rank\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Get first 5 examples\n",
    "first_5_pred = final_scores[:5]\n",
    "first_5_human = human_scores.iloc[:5]\n",
    "\n",
    "for i in range(min(5, len(final_scores))):\n",
    "    predicted = first_5_pred[i]\n",
    "    human = first_5_human.iloc[i]\n",
    "    \n",
    "    # Calculate ranks within these 5 examples (higher score = higher rank)\n",
    "    pred_rank = (first_5_pred > predicted).sum() + 1\n",
    "    human_rank = (first_5_human > human).sum() + 1\n",
    "    \n",
    "    print(f\"  {i+1}     | {predicted:.3f}    | {human:.3f} | {pred_rank:>9} | {human_rank:>10}\")\n",
    "\n",
    "# Check correlation with human scores\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "correlation, p_value = pearsonr(human_scores, final_scores)\n",
    "print(f\"\\nCorrelation with human scores: {correlation:.3f} (p={p_value:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae427c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "REPORT CARD\n",
      "==================================================\n",
      "\n",
      "# Autometrics Report Card\n",
      "\n",
      "## Dataset Information\n",
      "- **Dataset**: SimpDA\n",
      "- **Target Measure**: simplicity\n",
      "- **Dataset Size**: 434 examples\n",
      "\n",
      "## Top Metrics Selected\n",
      "- **1.** LENS\n",
      "- **2.** BERTScore_roberta-large (MultiMetric: BERTScoreP_roberta-large, BERTScoreR_roberta-large, BERTScoreF_roberta-large)\n",
      "- **3.** BLEU\n",
      "- **4.** ROUGE (MultiMetric: ROUGE-1-p, ROUGE-2-p, ROUGE-L-p, ROUGE-Lsum-p, ROUGE-1-r, ROUGE-2-r, ROUGE-L-r, ROUGE-Lsum-r, ROUGE-1-f1, ROUGE-2-f1, ROUGE-L-f1, ROUGE-Lsum-f1)\n",
      "- **5.** Perplexity_gpt2-large\n",
      "\n",
      "## Regression Aggregator\n",
      "- **Type**: ElasticNet\n",
      "- **Name**: Autometrics_Regression_simplicity\n",
      "- **Description**: Regression aggregator for simplicity using top 5 metrics\n",
      "\n",
      "## Summary\n",
      "The Autometrics pipeline successfully identified the most relevant metrics for evaluating simplicity on the SimpDA dataset. The selected metrics can be used individually or combined through the regression aggregator for comprehensive evaluation.\n",
      "\n",
      "## Hotelling TÂ² Selection\n",
      "- Selected variables: 18\n",
      "\n",
      "\n",
      "==================================================\n",
      "TUTORIAL COMPLETE!\n",
      "==================================================\n",
      "You now have:\n",
      "âœ… A custom metric for your task\n",
      "âœ… Top 5 most relevant metrics\n",
      "âœ… A final aggregated metric\n",
      "âœ… Correlation with human judgments\n",
      "\n",
      "You can use these metrics on new data!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"REPORT CARD\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(results['report_card'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TUTORIAL COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(\"You now have:\")\n",
    "print(\"âœ… A custom metric for your task\")\n",
    "print(\"âœ… Top 5 most relevant metrics\")\n",
    "print(\"âœ… A final aggregated metric\")\n",
    "print(\"âœ… Correlation with human judgments\")\n",
    "print(\"\\nYou can use these metrics on new data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a0fba9-bd46-4790-9986-6f02268849a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
