{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48ff42c0",
   "metadata": {},
   "source": [
    "# Policy Deep Research Rollout\n",
    "\n",
    "Run a single inference episode against the OpenEnv environment. Set `USE_OPENAI` to `True` to drive the env with an OpenAI ChatCompletions model (requires `OPENAI_API_KEY`), or keep it `False` to use a local Hugging Face model via `AutoModelForCausalLM`. Make sure you've already built the environment image with `openenv build --tag openenv-policy-deep-research-env:latest` and exported `S2_API_KEY` if you want Semantic Scholar access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2834ee94-ea5c-4f1f-93e3-fd62337e3b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using repo root: /Users/spangher/Projects/stanford-research/rfi-research/regulations-demo/scripts/policy-deep-research-agent\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def call_openai(messages, temperature):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        response_format={'type': 'json_object'},\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "REPO_ROOT = Path.cwd()\n",
    "if not (REPO_ROOT / 'training').exists():\n",
    "    for parent in REPO_ROOT.parents:\n",
    "        if (parent / 'training').exists():\n",
    "            REPO_ROOT = parent\n",
    "            break\n",
    "\n",
    "if not (REPO_ROOT / 'training').exists():\n",
    "    raise RuntimeError('Could not locate repo root containing training/. Start the notebook from the project root.')\n",
    "\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "print(f'Using repo root: {REPO_ROOT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a06da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Configuration ----\n",
    "USE_OPENAI = True                    # Toggle to use OpenAI ChatCompletions instead of a local HF model\n",
    "MODEL_ID = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
    "OPENAI_MODEL = 'gpt-5-mini'\n",
    "ENV_IMAGE = 'openenv-policy-deep-research-env:latest'\n",
    "USE_CACHED = True\n",
    "TASK_INDEX = 0\n",
    "MAX_STEPS = 12\n",
    "TEMPERATURE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6554319b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded prompts.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from training.rollout_openenv import rollout_openenv, _parse_action_payload, _format_feedback\n",
    "from src.envs.policy_deep_research_env.client import PolicyDeepResearchEnv\n",
    "from src.envs.policy_deep_research_env.models import ResearchAction\n",
    "\n",
    "system_prompt = (REPO_ROOT / 'training' / 'prompts' / 'system.txt').read_text().strip()\n",
    "example_path = REPO_ROOT / 'training' / 'prompts' / 'example_1.txt'\n",
    "if example_path.exists():\n",
    "    system_prompt = f\"{system_prompt}\\n\\n{example_path.read_text().strip()}\"\n",
    "action_schema = (REPO_ROOT / 'training' / 'prompts' / 'action_schema.md').read_text()\n",
    "print('Loaded prompts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21218eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "os.environ['OPENAI_API_KEY'] = open('/Users/spangher/.openai-reglab-project-key.txt').read().strip()\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "282da3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready.\n"
     ]
    }
   ],
   "source": [
    "env_client = PolicyDeepResearchEnv.from_docker_image(\n",
    "    ENV_IMAGE,\n",
    "    env_vars={\n",
    "        'OPENENV_USE_CACHED': '1' if USE_CACHED else '0',\n",
    "        'OPENENV_TASK_INDEX': str(TASK_INDEX),\n",
    "        'MAX_STEPS': str(MAX_STEPS),\n",
    "        'S2_API_KEY': os.getenv('S2_API_KEY', ''),\n",
    "    },\n",
    ")\n",
    "print('Environment ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bec98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role': 'system', 'content': system_prompt.strip()}]\n",
    "reset = env_client.reset()\n",
    "obs = reset.observation\n",
    "messages.append({'role': 'user', 'content': f\"{obs.question}\\n\\n{obs.instructions}\"})\n",
    "\n",
    "transcript = []\n",
    "final_reward = 0.0\n",
    "final_memo = ''\n",
    "steps = 0\n",
    "task_id = obs.task_id\n",
    "bib = []\n",
    "temperature=1\n",
    "\n",
    "while steps < 1:\n",
    "    completion = call_openai(messages, temperature)\n",
    "    transcript.append({'messages_snapshot': messages[-4:], 'completion': completion})\n",
    "    try:\n",
    "        action_dict, _ = _parse_action_payload(completion)\n",
    "    except ValueError as exc:\n",
    "        messages.append({'role': 'assistant', 'content': completion})\n",
    "        messages.append({'role': 'user', 'content': f\"Invalid JSON ({exc}). Return <action>{{...}}</action> matching:\\n{action_schema}\"})\n",
    "        continue\n",
    "\n",
    "    action = ResearchAction(**action_dict)\n",
    "    step = env_client.step(action)\n",
    "    obs = step.observation\n",
    "    steps += 1\n",
    "    bib = obs.bib\n",
    "    meta = obs.metadata or {}\n",
    "    if meta.get('final_memo'):\n",
    "        final_memo = meta.get('final_memo', '')\n",
    "    final_reward = float(step.reward or 0.0)\n",
    "    task_id = obs.task_id\n",
    "\n",
    "    messages.append({'role': 'assistant', 'content': completion})\n",
    "    messages.append({'role': 'user', 'content': _format_feedback(obs)})\n",
    "\n",
    "    if step.done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "126e4474-71ba-4d05-bb93-3d4ad83617ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResearchAction(metadata={}, type='SEARCH SEMANTIC_SCHOLAR', query='state carbon pricing revenue use resilience RGGI California cap-and-trade auction proceeds climate resilience coastal adaptation \"auction proceeds\" \"resilience\"', paper_id=None, top_k=10, filters={}, content=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2afbe9b-691a-4809-bde7-0b680016ce11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StepResult(observation=ResearchObservation(done=False, reward=None, metadata={}, task_id='policy_001', question='How are US states leveraging carbon pricing mechanisms to fund climate resilience?', instructions='Valid actions:\\n1) SEARCH SEMANTIC SCHOLAR - query Semantic Scholar for academic papers. Requires {\"type\":\"SEARCH SEMANTIC SCHOLAR\",\"query\":\"...\"}.\\n2) FETCH PAPER - fetch a specific paper. Requires {\"type\":\"FETCH PAPER\",\"paper_id\":\"...\"}.\\n3) ADD_TO_BIB - add a paper to your bibliography with a justification. Requires {\"type\":\"ADD_TO_BIB\",\"paper_id\":\"...\",\"metadata\":{\"reason\":\"...\"}}.\\n4) WRITE_NOTE - write a free-form note. Requires {\"type\":\"WRITE_NOTE\",\"content\":\"...\"}.\\n5) SUBMIT - deliver the final memo. Requires {\"type\":\"SUBMIT\",\"content\":\"...\"}.e.g.: <think>your private reasoning</think><action>{\"type\":\"...\"}</action>\\n\\n', last_tool_result={'error': 'Unknown action.type=SEARCH SEMANTIC_SCHOLAR'}, bib=[], notes=[], remaining_steps=11), reward=0.0, done=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0a19877-00ad-47d3-9de0-fb3a8fe1f3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{ \"error\": \"You must include a <think> tag followed by an <action> command in this turn.\" }'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfada094-b225-40c9-aafc-180d86914486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'SEARCH',\n",
       " 'query': \"US states carbon pricing revenues fund climate resilience academic papers reports 'Regional Greenhouse Gas Initiative' California cap-and-trade 'carbon fee' 'carbon pricing' 'resilience' 'adaptation' 'use of proceeds'\",\n",
       " 'metadata': {},\n",
       " 'filters': {},\n",
       " 'top_k': 10}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afe1fbbb-1c3b-4a85-aef7-3d3d2d16a668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "pyperclip.copy(str(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad674d1-eb99-40da-a5d1-4f747c684339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d668ceee-f00b-460b-9e4f-673046f65840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ec7f6e-c1c8-4ad9-85dc-76f80a35b93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7d06b0-5895-4a7a-9924-460f1de784b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce418a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: -1.0\n",
      "Task ID: policy_001\n",
      "Steps: 12\n",
      "Bibliography entries:\n",
      "Final memo snippet: \n"
     ]
    }
   ],
   "source": [
    "rollout = run_openai_episode(\n",
    "    env_client=env_client,\n",
    "    system_prompt=system_prompt,\n",
    "    action_schema=action_schema,\n",
    "    max_steps=MAX_STEPS,\n",
    "    temperature=TEMPERATURE,\n",
    ")\n",
    "reward = rollout['reward']\n",
    "final_memo = rollout.get('final_memo', '')\n",
    "\n",
    "print('Reward:', reward)\n",
    "print('Task ID:', rollout.get('task_id'))\n",
    "print('Steps:', rollout.get('steps'))\n",
    "print('Bibliography entries:')\n",
    "for paper in rollout.get('bib', []):\n",
    "    print('-', paper.get('title'), paper.get('paperId'))\n",
    "print('Final memo snippet:', (final_memo or '')[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe2eb1-ae61-4d99-8916-30ae25277596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42f078f-6116-463e-8922-a105d7c03258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7438705-32fb-4eb3-809c-f907d283b2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd40441-85c4-4fdc-8225-bf711cdf758d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_client.close()\n",
    "print('Environment closed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
