{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48ff42c0",
   "metadata": {},
   "source": [
    "# Policy Deep Research Rollout\n",
    "\n",
    "Run a single inference episode against the OpenEnv environment. Set `USE_OPENAI` to `True` to drive the env with an OpenAI ChatCompletions model (requires `OPENAI_API_KEY`), or keep it `False` to use a local Hugging Face model via `AutoModelForCausalLM`. Make sure you've already built the environment image with `openenv build --tag openenv-policy-deep-research-env:latest` and exported `S2_API_KEY` if you want Semantic Scholar access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2834ee94-ea5c-4f1f-93e3-fd62337e3b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using repo root: /Users/spangher/Projects/stanford-research/rfi-research/regulations-demo/scripts/policy-deep-research-agent\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def call_openai(messages, temperature):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        # response_format={'type': 'json_object'},\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "REPO_ROOT = Path.cwd()\n",
    "if not (REPO_ROOT / 'training').exists():\n",
    "    for parent in REPO_ROOT.parents:\n",
    "        if (parent / 'training').exists():\n",
    "            REPO_ROOT = parent\n",
    "            break\n",
    "\n",
    "if not (REPO_ROOT / 'training').exists():\n",
    "    raise RuntimeError('Could not locate repo root containing training/. Start the notebook from the project root.')\n",
    "\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "print(f'Using repo root: {REPO_ROOT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a06da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Configuration ----\n",
    "USE_OPENAI = True                    # Toggle to use OpenAI ChatCompletions instead of a local HF model\n",
    "MODEL_ID = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
    "OPENAI_MODEL = 'gpt-5-mini'\n",
    "ENV_IMAGE = 'openenv-policy-deep-research-env:latest'\n",
    "USE_CACHED = True\n",
    "TASK_INDEX = 0\n",
    "MAX_STEPS = 12\n",
    "TEMPERATURE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6554319b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded prompts.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from training.rollout_openenv import rollout_openenv, _parse_action_payload, _format_feedback\n",
    "from src.envs.policy_deep_research_env.client import PolicyDeepResearchEnv\n",
    "from src.envs.policy_deep_research_env.models import ResearchAction\n",
    "\n",
    "system_prompt = (REPO_ROOT / 'training' / 'prompts' / 'system.txt').read_text().strip()\n",
    "example_path = REPO_ROOT / 'training' / 'prompts' / 'example_1.txt'\n",
    "if example_path.exists():\n",
    "    system_prompt = f\"{system_prompt}\\n\\n{example_path.read_text().strip()}\"\n",
    "action_schema = (REPO_ROOT / 'training' / 'prompts' / 'action_schema.md').read_text()\n",
    "print('Loaded prompts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21218eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "os.environ['OPENAI_API_KEY'] = open('/Users/spangher/.openai-reglab-project-key.txt').read().strip()\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "282da3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready.\n"
     ]
    }
   ],
   "source": [
    "env_client = PolicyDeepResearchEnv.from_docker_image(\n",
    "    ENV_IMAGE,\n",
    "    env_vars={\n",
    "        'OPENENV_USE_CACHED': '1' if USE_CACHED else '0',\n",
    "        'OPENENV_TASK_INDEX': str(TASK_INDEX),\n",
    "        'MAX_STEPS': str(MAX_STEPS),\n",
    "        'S2_API_KEY': os.getenv('S2_API_KEY', ''),\n",
    "    },\n",
    ")\n",
    "print('Environment ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bec98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{'role': 'system', 'content': system_prompt.strip()}]\n",
    "reset = env_client.reset()\n",
    "obs = reset.observation\n",
    "messages.append({'role': 'user', 'content': f\"{obs.question}\\n\\n{obs.instructions}\"})\n",
    "\n",
    "transcript = []\n",
    "final_reward = 0.0\n",
    "final_memo = ''\n",
    "steps = 0\n",
    "task_id = obs.task_id\n",
    "bib = []\n",
    "temperature=1\n",
    "\n",
    "def run_one_round(messages):\n",
    "    completion = call_openai(messages, temperature)\n",
    "    transcript.append({'messages_snapshot': messages[-4:], 'completion': completion})\n",
    "    action_dict, _ = _parse_action_payload(completion)\n",
    "    action = ResearchAction(**action_dict)\n",
    "    step = env_client.step(action)\n",
    "    return completion, action, step\n",
    "\n",
    "while steps < 1:\n",
    "    completion, action, step = run_one_round(messages)\n",
    "    obs = step.observation\n",
    "    steps += 1\n",
    "    bib = obs.bib\n",
    "    meta = obs.metadata or {}\n",
    "    if meta.get('final_memo'):\n",
    "        final_memo = meta.get('final_memo', '')\n",
    "    final_reward = float(step.reward or 0.0)\n",
    "    task_id = obs.task_id\n",
    "    \n",
    "    messages.append({'role': 'assistant', 'content': completion})\n",
    "    messages.append({'role': 'user', 'content': _format_feedback(obs)})\n",
    "\n",
    "    if step.done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a02dcd24-5de8-44ae-9ece-069d91fc8bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion, action, step = run_one_round(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab354f0e-2ee1-444b-bfe5-08da7a65861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = step.observation\n",
    "steps += 1\n",
    "bib = obs.bib\n",
    "meta = obs.metadata or {}\n",
    "if meta.get('final_memo'):\n",
    "    final_memo = meta.get('final_memo', '')\n",
    "final_reward = float(step.reward or 0.0)\n",
    "task_id = obs.task_id\n",
    "\n",
    "messages.append({'role': 'assistant', 'content': completion})\n",
    "messages.append({'role': 'user', 'content': _format_feedback(obs)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cd7ca1d-2ded-4829-b38c-4d736fd11ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>I will search for papers or policy analyses on RGGI proceeds and how states use them for resilience or adaptation funding.</think>\\n<action>{\"type\":\"SEARCH SEMANTIC_SCHOLAR\",\"query\":\"RGGI proceeds resilience adaptation funding\"}</action>'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df98bb73-3020-47d3-8ea1-ef88ecb65e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RGGI proceeds resilience adaptation funding'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71ca4b47-e580-46a5-bce7-3a31049bbf3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StepResult(observation=ResearchObservation(done=False, reward=None, metadata={}, task_id='policy_001', question='How are US states leveraging carbon pricing mechanisms to fund climate resilience?', instructions='Valid actions:\\n1) SEARCH SEMANTIC SCHOLAR - query Semantic Scholar for academic papers. Use SHORT, KEYWORD-FOCUSED queries (3â€“6 terms). Avoid punctuation like quotes or OR clauses. Be sure to keep your queries short!!! Requires {\"type\":\"SEARCH SEMANTIC SCHOLAR\",\"query\":\"...\"}.\\n2) FETCH SEMANTIC SCHOLAR PAPER - fetch a specific semantic scholar paper from the search results. Requires {\"type\":\"FETCH SEMANTIC SCHOLAR PAPER\",\"paper_id\":\"...\"}.\\n3) ADD TO BIB - add a paper to your bibliography with a justification. Requires {\"type\":\"ADD TO BIB\",\"paper_id\":\"...\",\"metadata\":{\"reason\":\"...\"}}.\\n4) WRITE NOTE - write a free-form note. Requires {\"type\":\"WRITE NOTE\",\"content\":\"...\"}.\\n5) SUBMIT - deliver the final memo. Requires {\"type\":\"SUBMIT\",\"content\":\"...\"}.\\n', last_tool_result={'type': 'search_results', 'query_id': 'c51e79b5b40f811be26a2ef0bca6d7c6ac27ea7fb55943efcbf5767f7bfbe528', 'query': 'RGGI proceeds resilience adaptation funding', 'results': [], 'cached': False}, bib=[], notes=[], remaining_steps=7), reward=0.0, done=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2c904b7-b1ab-4848-83d9-3cd8130ebd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_api_key = open('/Users/spangher/.s2_api_key.txt').read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "112b0d80-9085-4528-a2b0-744aa364fce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 'RGGI proceeds resilience adaptation funding' returned 1 result(s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'paperId': '527dc99b95d2e9a1cf37b619d0acfac22d92fe60',\n",
       "  'title': 'Argentina - Adaptation Fund: Increasing Climate Resilience and Enhancing Sustainable Land Management in the Southwest of the Buenos Aires Province Project : restructuring',\n",
       "  'year': 2018,\n",
       "  'url': 'https://www.semanticscholar.org/paper/527dc99b95d2e9a1cf37b619d0acfac22d92fe60',\n",
       "  'authors': 'Tuuli Johanna Bernardini'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_semantic_scholar_search(query=action.query, api_key=s2_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b632ef-7dcb-44b8-97b6-de1fb9832b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe2eb1-ae61-4d99-8916-30ae25277596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42f078f-6116-463e-8922-a105d7c03258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0b3b6f5-1b95-4298-8be3-2a14dfc9dd20",
   "metadata": {},
   "source": [
    "# Test Semantic Scholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75f85835-3ad6-4ef7-8001-e7b96f628e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def test_semantic_scholar_search(query: str, limit: int = 5, fields: str | None = None, api_key: str | None = None):\n",
    "    \"\"\"Fire a basic Semantic Scholar search to verify API/key wiring.\"\"\"\n",
    "    api_key = api_key or os.getenv('S2_API_KEY')\n",
    "    headers = {'x-api-key': api_key} if api_key else {}\n",
    "    params = {\n",
    "        'query': query,\n",
    "        'limit': limit,\n",
    "        'fields': fields or 'title,year,authors.name,url',\n",
    "    }\n",
    "    url = 'https://api.semanticscholar.org/graph/v1/paper/search'\n",
    "    response = requests.get(url, params=params, headers=headers, timeout=10)\n",
    "    response.raise_for_status()\n",
    "    payload = response.json()\n",
    "    results = []\n",
    "    for item in payload.get('data', []):\n",
    "        authors = ', '.join(author.get('name', '') for author in item.get('authors', []) if author.get('name'))\n",
    "        results.append(\n",
    "            {\n",
    "                'paperId': item.get('paperId'),\n",
    "                'title': item.get('title'),\n",
    "                'year': item.get('year'),\n",
    "                'url': item.get('url'),\n",
    "                'authors': authors,\n",
    "            }\n",
    "        )\n",
    "    print(f\"Query '{query}' returned {len(results)} result(s).\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd40441-85c4-4fdc-8225-bf711cdf758d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_client.close()\n",
    "print('Environment closed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
